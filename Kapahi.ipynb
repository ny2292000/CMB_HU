{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac43c1d-af3b-473e-b20d-d74b7c81e50a",
   "metadata": {},
   "source": [
    "# V. K. Kapahi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec540e59-8c31-4ea0-be50-8641c1088fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess the image for better OCR accuracy.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert(\"L\")  # Convert to grayscale\n",
    "    image = image.filter(ImageFilter.SHARPEN)  # Sharpen the image\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(2)  # Enhance contrast\n",
    "    return image\n",
    "\n",
    "def ocr_tables_to_dataframe(image_paths):\n",
    "    rows = []\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        # Preprocess image\n",
    "        image = preprocess_image(image_path)\n",
    "        # OCR the image with specific parameters for tables\n",
    "        ocr_text = pytesseract.image_to_string(image, config=\"--psm 6\")\n",
    "\n",
    "        print(f\"OCR Text from {image_path}:\")  # Debug: Print raw OCR text\n",
    "        print(ocr_text)\n",
    "\n",
    "        # Process each line of the OCR text\n",
    "        for line in ocr_text.splitlines():\n",
    "            print(f\"Processing line: {line}\")  # Debug: Print each line being processed\n",
    "            # Regex to parse table rows (Source, Redshift, Angular Size, etc.)\n",
    "            match = re.match(r\"([\\w+\\-]+)\\s+[\\d\\.]+\\s+[\\d\\.]+\\s+(G|Q)\\s+([\\d\\.\\(\\)]+)\\s+<?\\s?([\\d\\.]+)\", line)\n",
    "            if match:\n",
    "                try:\n",
    "                    source = match.group(1)\n",
    "                    id_type = match.group(2)  # G for Galaxy, Q for Quasar\n",
    "                    redshift = float(match.group(3).replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "                    angular_size = float(match.group(4).replace(\"<\", \"\").replace(\">\", \"\"))\n",
    "                    rows.append({\"Source\": source, \"ID\": id_type, \"Redshift\": redshift, \"Angular_Size\": angular_size})\n",
    "                except (ValueError, AttributeError):\n",
    "                    print(f\"Skipping line due to error: {line}\")  # Log problematic lines\n",
    "                    continue\n",
    "    \n",
    "    # Create a DataFrame from the parsed rows\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Paths to the image files\n",
    "# Extract text from each image\n",
    "image_paths = [\n",
    "        # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image1.png\",\n",
    "        \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image2.png\",\n",
    "        # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image3.png\",\n",
    "        # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image4.png\",\n",
    "        # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image5.png\",\n",
    "        # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image6.png\",\n",
    "        # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image7.png\",\n",
    "        # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image8.png\",\n",
    "]\n",
    "\n",
    "# Create the DataFrame by processing the images\n",
    "dataframe = ocr_tables_to_dataframe(image_paths)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb91a7f-afe8-4e86-a7a9-232fedcc6c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c236d3a-5253-46bb-baba-0a65e02fb571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess the image for better OCR accuracy.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert(\"L\")  # Convert to grayscale\n",
    "    image = image.filter(ImageFilter.SHARPEN)  # Sharpen the image\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(2)  # Enhance contrast\n",
    "    return image\n",
    "\n",
    "def parse_fixed_length_columns(line):\n",
    "    \"\"\"Parse a line of text using fixed-length column slicing.\"\"\"\n",
    "    try:\n",
    "        source = line[0:10].strip()\n",
    "        id_type = line[30:31].strip()  # Assuming ID is always one character (G/Q)\n",
    "        redshift = float(line[40:47].strip().replace(\";\", \"\"))  # Clean any semicolons or spaces\n",
    "        angular_size = float(line[48:].strip().replace(\"<\", \"\").replace(\">\", \"\"))\n",
    "        print( \"succeded\", source, \"    :   \", id_type,  \"    :   \", redshift, \"    :   \",angular_size)\n",
    "        return {\"Source\": source, \"ID\": id_type, \"Redshift\": redshift, \"Angular_Size\": angular_size}\n",
    "    except ValueError:\n",
    "        print( \"failed\", source, \"    :   \", id_type,  \"    :   \", redshift, \"    :   \",angular_size)\n",
    "        return None\n",
    "\n",
    "def ocr_tables_to_dataframe(image_paths):\n",
    "    rows = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Preprocess image\n",
    "        image = preprocess_image(image_path)\n",
    "        # OCR the image with specific parameters for tables\n",
    "        ocr_text = pytesseract.image_to_string(image, config=\"--psm 6\")\n",
    "\n",
    "        print(f\"OCR Text from {image_path}:\")  # Debug: Print raw OCR text\n",
    "        print(ocr_text)\n",
    "\n",
    "        # Process each line of the OCR text\n",
    "        for line in ocr_text.splitlines():\n",
    "            print(f\"Processing line: {line}\")  # Debug: Print each line being processed\n",
    "            parsed_row = parse_fixed_length_columns(line)\n",
    "            if parsed_row:\n",
    "                rows.append(parsed_row)\n",
    "\n",
    "    # Create a DataFrame from the parsed rows\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Paths to the image files\n",
    "image_paths = [\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image1.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image2.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image3.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image4.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image5.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image6.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image7.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image8.png\"\n",
    "]\n",
    "\n",
    "# Create the DataFrame by processing the images\n",
    "dataframe = ocr_tables_to_dataframe(image_paths)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89506aaf-a024-4df0-99e6-bd1701b2362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess the image for better OCR accuracy.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.convert(\"L\")  # Convert to grayscale\n",
    "    image = image.filter(ImageFilter.SHARPEN)  # Sharpen the image\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(2)  # Enhance contrast\n",
    "    return image\n",
    "\n",
    "def parse_line_with_flexibility(line):\n",
    "    \"\"\"Parse a line of text dynamically, accounting for missing columns.\"\"\"\n",
    "    try:\n",
    "        # Regex to extract the Source, ID, Redshift, and Angular Size dynamically\n",
    "        pattern = r\"(\\S{4,10})\\s+(\\d*\\.\\d+)?\\s+(\\d*\\.\\d+)?\\s+(G|Q)\\s+(\\d*\\.\\d+|\\(\\d*\\.\\d+\\))\\s+(\\d+)\"\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            source = match.group(1)\n",
    "            id_type = match.group(4)  # G for Galaxy, Q for Quasar\n",
    "            redshift = float(match.group(5).replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "            angular_size = float(match.group(6).replace(\"<\", \"\").replace(\">\", \"\"))\n",
    "            return {\"Source\": source, \"ID\": id_type, \"Redshift\": redshift, \"Angular_Size\": angular_size}\n",
    "    except ValueError:\n",
    "        pass  # Skip lines that don't match the expected format\n",
    "    return None\n",
    "\n",
    "def ocr_tables_to_dataframe(image_paths):\n",
    "    rows = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Preprocess image\n",
    "        image = preprocess_image(image_path)\n",
    "        # OCR the image with specific parameters for tables\n",
    "        ocr_text = pytesseract.image_to_string(image, config=\"--psm 6\")\n",
    "\n",
    "        print(f\"OCR Text from {image_path}:\")  # Debug: Print raw OCR text\n",
    "        print(ocr_text)\n",
    "\n",
    "        # Process each line of the OCR text\n",
    "        for line in ocr_text.splitlines():\n",
    "            print(f\"Processing line: {line}\")  # Debug: Print each line being processed\n",
    "            parsed_row = parse_line_with_flexibility(line)\n",
    "            if parsed_row:\n",
    "                rows.append(parsed_row)\n",
    "\n",
    "    # Create a DataFrame from the parsed rows\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Paths to the image files\n",
    "image_paths = [\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/table3.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image1.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image2.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image3.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image4.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image5.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image6.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image7.png\",\n",
    "    # \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/image8.png\"\n",
    "]\n",
    "\n",
    "# Create the DataFrame by processing the images\n",
    "dataframe = ocr_tables_to_dataframe(image_paths)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a0810-0697-41a3-af9f-3b91646153df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d513a6-5a28-4ccd-9c4d-5b478cb63e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Adjust columns and handle potential formatting issues\n",
    "file_path = \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/Kapahi.txt\"\n",
    "columns = [\"Source\", \"ID\", \"Redshift\", \"Angular_Size\"]\n",
    "\n",
    "# Load the cleaned data into a DataFrame\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Process the lines manually to ensure proper parsing\n",
    "data = []\n",
    "for line in lines:\n",
    "    parts = line.split(\" \")\n",
    "    if len(parts) == 6:  # Ensure the line has the correct number of columns\n",
    "        data.append({\n",
    "            \"Source\": parts[0],\n",
    "            \"Redshift\": parts[1].replace(\"(\", \"\").replace(\")\", \"\"),\n",
    "            \"Angular_Size\": parts[2].replace(\"<\", \"\").replace(\">\", \"\"),\n",
    "            \"ID\": parts[3],\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "dataframe = pd.DataFrame(data)\n",
    "\n",
    "# Filter for galaxies (ID = \"G\")\n",
    "# Create a copy of the filtered DataFrame before modifying it\n",
    "galaxy_data = dataframe[dataframe[\"ID\"] == \"G\"].copy()\n",
    "\n",
    "# Convert numerical columns to float for further analysis\n",
    "galaxy_data[\"Redshift\"] = pd.to_numeric(galaxy_data[\"Redshift\"], errors=\"coerce\")\n",
    "galaxy_data[\"Angular_Size\"] = pd.to_numeric(galaxy_data[\"Angular_Size\"], errors=\"coerce\")\n",
    "galaxy_data = galaxy_data[galaxy_data.Redshift <15]\n",
    "\n",
    "# Display the filtered DataFrame to the user\n",
    "# Display the DataFrame using pandas\n",
    "print(galaxy_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0ee6f-40c2-4d69-8a2a-f15e84de9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Adjust columns and handle potential formatting issues\n",
    "file_path = \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/Kapahi_table3.txt\"\n",
    "columns = [\"Source\", \"Angular_Size\", \"BestAngularSize\"]\n",
    "\n",
    "# Load the cleaned data into a DataFrame\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Process the lines manually to ensure proper parsing\n",
    "data = []\n",
    "for line in lines:\n",
    "    parts = line.split(\" \")\n",
    "    if len(parts) == 3:  # Ensure the line has the correct number of columns\n",
    "        data.append({\n",
    "            \"Source\": parts[0],\n",
    "            \"Angular_Size\": parts[1],\n",
    "            \"Best_Angular_Size\": parts[2],\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert numerical columns to float for further analysis\n",
    "df[\"Angular_Size\"] = pd.to_numeric(df[\"Angular_Size\"], errors=\"coerce\")\n",
    "df[\"Best_Angular_Size\"] = pd.to_numeric(df[\"Best_Angular_Size\"], errors=\"coerce\")\n",
    "\n",
    "# Display the filtered DataFrame to the user\n",
    "# Display the DataFrame using pandas\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c30722-3e0e-4db6-9da5-b42ab0d8c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_data.plot(\"Redshift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e19ad-0e5d-4806-a883-ce13d55a1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to extract and organize the data from the tables in the document\n",
    "\n",
    "# Define a function to bin the data by redshift and calculate medians\n",
    "def bin_and_calculate_medians(df, bin_size):\n",
    "    df['Bin'] = (df['Redshift'] / bin_size).astype(int) * bin_size\n",
    "    grouped = df.groupby('Bin')['Angular_Size'].median()\n",
    "    return grouped\n",
    "\n",
    "# Define a function to plot the data\n",
    "def plot_data(grouped_data):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(grouped_data.index, grouped_data.values, marker='o', linestyle='-', label='Median Angular Size')\n",
    "    plt.xlabel('Redshift (z)')\n",
    "    plt.ylabel('Median Angular Size (arcsec)')\n",
    "    plt.title('Median Angular Size vs. Redshift')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Main function to execute the workflow\n",
    "\n",
    "# Step 1: Extract data\n",
    "df = galaxy_data\n",
    "\n",
    "# Step 2: Bin data and calculate medians\n",
    "bin_size = 0.1\n",
    "grouped_data = bin_and_calculate_medians(df, bin_size)\n",
    "\n",
    "# Step 3: Plot the data\n",
    "plot_data(grouped_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e848eba3-354c-4701-8f62-1a3725cc833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "# Reload the newly uploaded image and perform OCR\n",
    "image_path = \"/mnt/sda1/Dropbox/AAA_Papers_2022_Folder/AAA_CMB_HU_latest_to_git/KapahiData/table3.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Perform OCR with the appropriate configuration\n",
    "ocr_text = pytesseract.image_to_string(image, config=\"--psm 6\")\n",
    "\n",
    "# Display the OCR output to see what was extracted\n",
    "ocr_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd2ac4-180e-4970-9123-a6b246160cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72acbba2-4e29-4a05-b55d-880dc01df30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ba1b2-4f0d-4635-90e6-3524fe110065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23186ff6-af20-4895-86e9-7496a7dbcf35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d7536-07bb-4117-a269-29d1c36ebe0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b210932b-df63-4bbf-be21-13740f2d1e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede4f12-d66c-4ae1-84ee-3dccbf4502b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96fba5-ce4f-423e-b5b7-96f13fb62ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644c6e2-cc26-4d5d-904f-f90ab0324920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the DataFrame: remove any rows with invalid redshift or angular size values\n",
    "df_cleaned = df_extracted.dropna()\n",
    "df_cleaned = df_cleaned[df_cleaned['Redshift'] > 0]  # Ensure positive redshift values\n",
    "df_cleaned = df_cleaned[df_cleaned['Angular_Size'] > 0]  # Ensure positive angular size values\n",
    "\n",
    "# Binning the data by redshift\n",
    "bin_size = 0.3\n",
    "df_cleaned['Bin'] = (df_cleaned['Redshift'] // bin_size) * bin_size\n",
    "\n",
    "# Calculating the median angular size for each bin\n",
    "binned_data_cleaned = df_cleaned.groupby('Bin')['Angular_Size'].median()\n",
    "\n",
    "# Plotting the cleaned and processed data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(binned_data_cleaned.index, binned_data_cleaned.values, marker='o', linestyle='-', label='Median Angular Size')\n",
    "plt.xlabel('Redshift (z)')\n",
    "plt.ylabel('Median Angular Size (arcsec)')\n",
    "plt.title('Median Angular Size vs. Redshift (Cleaned Data)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b99fd-8918-46f7-ac1d-87c27664fb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5979a38-54a8-496f-8ee1-ea6f90b6d74f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Cosmos3020]",
   "language": "python",
   "name": "conda-env-Cosmos3020-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
